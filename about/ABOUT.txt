
Code to extract some linguistic features related to linguistic complexity of English texts. This project contains a cleaner version of the code for various parts of my PhD thesis and attempts to integrate code written by others in the department on related issues, implementing different features. 


* The following features are implemented as of now: 
 - Lexical Richness and Syntactic Complexity features explained in Lu-12 and Lu-10
 - Several other POS tag density and constituent tree based features.
 - Celex - Morph and Syntactic features
 - Psycholinguistic features (Age of Acquisition and others)
 - Traditional features (word length in characters and syllables, sentence length, traditional formulae)
 - Word frequency based features.
 - Content overlap features
 - Referential cohesion based features

* Notes about the comparison with my thesis (Vajjala, 2015): While the numbers may slightly differ now because of the change in the tools and versions, For Celex-Syntactic features, they will change more, because I realized that I had the denominator as numSentences instead of numWordsConsidered there until now! AoA_Kup and AoA_Kup_Lem were earlier showing same result - this is changed now.
 
Code from other people, used in this project:
* Traditional Readability features: Niels Ott (including the syllable counter from Laura kassner) - Phantom Library.
* MTLD (Mean Textual Lexical Diversity) implementation from Julia Hancke. - in WordBasedFeatures.java method.


* List of folders and their description:
  a)src/utils: is a general purpose utils folder, which can be used outside the context of this project as well.
	
	src/features: is the folder containing implementations for different classes of features.
	
	src/features/trad: is the folder containing traditional features from Niels Ott. 
	It uses a different sentence splitter (sptools in lib/). I did not change anything in this code except for getting numSyllables seperately as an extra variable.
	
	src/preprocessing: 
	
	src/wrappers: contains wrapper classes that actually input and output stuff.
	
	src/utils/genutils: classes that can be used to extract text from various formats. Preferably returns plain text.
	
  b) about/ : Some documentation about the project.
  c) lib/ : contains the necessary lib files.
I:q!
I  d) models/ : contains tagger and parser models used.
  e) resources/ : contains the databases, dictionaries used.
  
* List of tools and APIs used and their description:
	- Stanford tools: parser, tregex (All in Version 3.2) (http://nlp.stanford.edu/software/)
	- MIT Java API for Wordnet (version 2.3.3) (http://projects.csail.mit.edu/jwi/)
	- weka.jar
        - relevant licenses are in licenses/ directory

* How to cite if someone uses any parts of this code:
  Sowmya Vajjala and Detmar Meurers. 2014. Readability Assessment for Text Simplification: From Analyzing Documents to Identifying Sentential Simplifications. International Journal of Applied Linguistics, Special Issue on Current Research in Readability and Text Simplification edited by Thomas François and Delphine Bernhard. 165(2). 194-222. 
Journal version: https://benjamins.com/#catalog/journals/itl.165.2.04vaj/details
Local copy of the pdf: http://www.sfs.uni-tuebingen.de/~dm/papers/Vajjala.Meurers-14-ijal.html


* TODO: 
- Add LFP and some word lists from Niels’ MA thesis.
- Add Entity coherence features from Doreene Amati’s BA thesis (2014).
- Add Coreference features from Eyal Schejter’s BA thesis (2015).
	
* Contact: sowmya@sfs.uni-tuebingen.de